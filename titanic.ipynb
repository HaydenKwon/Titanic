{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T05:59:48.557137Z","iopub.execute_input":"2022-01-11T05:59:48.557411Z","iopub.status.idle":"2022-01-11T05:59:48.567718Z","shell.execute_reply.started":"2022-01-11T05:59:48.557385Z","shell.execute_reply":"2022-01-11T05:59:48.566804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nfull_set = [train_data,test_data]\ntrain_data.head()\n\nfor dataset in full_set:\n    dataset['Alone'] = 0\n    dataset['FamilySize'] = dataset['Parch'] + dataset['SibSp'] + 1\n    dataset.loc[dataset['FamilySize'] == 1, 'Alone'] = 1\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    avg_age = dataset['Age'].mean()\n    std_age = dataset['Age'].std()\n    null_count_age = dataset['Age'].isnull().sum()\n    age_null_list = np.random.randint(avg_age - std_age,avg_age + std_age, size = null_count_age)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_list\n    \n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset['Fare'] = dataset['Fare'].fillna(train_data['Fare'].median())\n\ntrain_data['Age_Categories'] = pd.cut(train_data['Age'],5)\n    \n    \nfor dataset in full_set:\n    print(dataset.columns[dataset.isnull().any()])\n##Missing Values\nprint(train_data[['Age_Categories', 'Survived']].groupby(['Age_Categories'], as_index=False).mean())\n\ntrain_data.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:59:48.569643Z","iopub.execute_input":"2022-01-11T05:59:48.570159Z","iopub.status.idle":"2022-01-11T05:59:48.627088Z","shell.execute_reply.started":"2022-01-11T05:59:48.570117Z","shell.execute_reply":"2022-01-11T05:59:48.62629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_title(name):\n    title = re.search(' ([A-Za-z]+)\\.', name)\n    if(title):\n        return title.group(1)\n    else:\n        return \"\"\n    \nfor dataset in full_set:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n     'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'VIP')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \nprint(pd.crosstab(train_data['Title'], train_data['Sex']))\nprint (train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\ntrain_data.head()\nprint(train_data['Sex'])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:59:48.628354Z","iopub.execute_input":"2022-01-11T05:59:48.628879Z","iopub.status.idle":"2022-01-11T05:59:48.662531Z","shell.execute_reply.started":"2022-01-11T05:59:48.628841Z","shell.execute_reply":"2022-01-11T05:59:48.661579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean data and map to numerical values\nfor dataset in full_set:\n    \n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} )\n\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} )\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:59:48.664237Z","iopub.execute_input":"2022-01-11T05:59:48.664551Z","iopub.status.idle":"2022-01-11T05:59:48.692862Z","shell.execute_reply.started":"2022-01-11T05:59:48.66451Z","shell.execute_reply":"2022-01-11T05:59:48.692222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_set:\n    dataset['Sex'] = dataset['Sex'].astype(int)\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset['Title'] = dataset['Title'].astype(int)\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    dataset['Age'] = dataset['Age'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:59:48.69423Z","iopub.execute_input":"2022-01-11T05:59:48.695471Z","iopub.status.idle":"2022-01-11T05:59:48.704066Z","shell.execute_reply.started":"2022-01-11T05:59:48.695427Z","shell.execute_reply":"2022-01-11T05:59:48.703349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\n#setup model and hyperparameter optimization\nparam_grid = {\n    'n_estimators': range(8, 20),\n    'max_depth': range(6, 10),\n    'learning_rate': [.4, .45, .5, .55, .6],\n    'colsample_bytree': [.6, .7, .8, .9, 1]\n}\n\nX_train = train_data[['Pclass',  'Sex',  'Age',  'Fare',  'Embarked',  'Alone',  'Title']]\ny_train = train_data[['Survived']]\n\n\nregressor = XGBClassifier(n_estimators = 10)\n\nxgb_random = RandomizedSearchCV(param_distributions=param_grid, \n                                    estimator = regressor, scoring = \"accuracy\", \n                                    verbose = 1, n_iter = 50, cv = 4)\nxgb_random.fit(X_train,y_train)\nprint(\"Best parameters found: \", xgb_random.best_params_)\nprint(\"Best accuracy found: \", xgb_random.best_score_)\n#Best parameters found:  {'n_estimators': 17, 'max_depth': 7, 'learning_rate': 0.55, 'colsample_bytree': 1}\n#Best accuracy found:  0.8238344847089242\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T05:59:48.705604Z","iopub.execute_input":"2022-01-11T05:59:48.706041Z","iopub.status.idle":"2022-01-11T06:00:00.629397Z","shell.execute_reply.started":"2022-01-11T05:59:48.705998Z","shell.execute_reply":"2022-01-11T06:00:00.628057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\npredictions = my_model.predict(X_valid)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:00:00.630442Z","iopub.execute_input":"2022-01-11T06:00:00.630637Z","iopub.status.idle":"2022-01-11T06:00:00.646305Z","shell.execute_reply.started":"2022-01-11T06:00:00.630613Z","shell.execute_reply":"2022-01-11T06:00:00.645184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\nprint(train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\nprint(train_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean())\nprint(train_data[['Alone', 'Survived']].groupby(['Alone'], as_index=False).mean())\nprint(train_data[['Fare', 'Survived']].groupby(['Fare'], as_index=False).mean())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:00:00.647553Z","iopub.status.idle":"2022-01-11T06:00:00.648621Z","shell.execute_reply.started":"2022-01-11T06:00:00.648309Z","shell.execute_reply":"2022-01-11T06:00:00.648338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_data.loc[train_data['Cabin'].isna()]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:00:00.650433Z","iopub.status.idle":"2022-01-11T06:00:00.651247Z","shell.execute_reply.started":"2022-01-11T06:00:00.650992Z","shell.execute_reply":"2022-01-11T06:00:00.651018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}